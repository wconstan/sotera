<style>
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}


.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 90%;
    text-align:center; width:100%;
}


.small-code pre code {
  font-size: 1em;
}

.super-small-code pre code {
  font-size: 0.6em;
}

.reveal h1, .reveal h2, .reveal h3 {
  word-wrap: normal;
  -moz-hyphens: none;
}

</style>


Sotera Defense Solutions: Twitter Homework
========================================================
author: William Constantine
date: September 7, 2016
width: 1200
height: 700
font-family: 'Helvetica'

Problem statement
========================================================
transition: zoom

- Identify high-volume Tweeters in the greater Seattle area that geotag their Tweets.

- Collect historical Tweets for a selected high-volume user and divide the geotagged latitude-longitude locations 
of their Tweets into regions (nearest one hundredth of a degree in lat-long coordinates).

- Use the Tweet information to estimate the probability that the user is in these regions given the data.

- Submit scripts used to identify high-volume users, obtain the data, and perform the calculations.

- Write the output to a text file containing three columns: lat, lon, percentage.

General approach
========================================================

- Obtain Twitter and Twitter Developer Account
<https://twitter.com/sotto_voce_vita>

- Develop faux Twitter application to obtain API keys 
<https://apps.twitter.com/app/12776987>

- Develop R script(s) to 
  * Collect, summarize and clean Twitter data
  * Collect supplementary data that may be useful in modeling the user's behavior
  * Build a classification model using the procured training data
  * Score the model to form regional probablities
  * Write scored output to text file

Collecting Twitter data
========================================================
class: small-code

I used the **streamR::filterStream** function to open a connection to Twitter's Streaming API, which returns public statuses that match one or more filter predicates. In particular, I used the **locations** and **timeout** filters to collect streaming data for five minutes around the Seattle area:

```{r, eval=FALSE}
# Get latitude-longitude bounding box of various counties in Washington state
state <- 'washington'
regions <- c('Snohomish','King','Pierce','Kitsap','Thurston','Mason')
locations <- get_bounds(state = state, regions = regions)

# Get tweets within bounding box for 5 minutes via stream filtering
tweets <- data.table(parseTweets(
  filterStream("", locations = locations, timeout = 300, oauth = credentials), verbose = FALSE))
tweets[1:10, list(text, screen_name, statuses_count, lat, lon)]
```

Sample stream output
========================================================
class: small-code
```{r, echo=FALSE}
library(data.table)
load(file = 'stream_sample.RData')
print(stream_sample)
```

Isolation of geotagged high-volume users
========================================================
class: small-code
```{r, eval=FALSE}
# Obtain only the Tweets that have geotagged tweets and 
# filter out descriptions that appear to be job related
tweets_geo_tagged <- tweets[!is.na(lat) & !is.na(lon), ]
filtered_tweets <- tweets_geo_tagged[!grepl('geo-targeted|jobs|careers', 
                                            description, ignore.case = TRUE)]

# order by the status_count
filtered_tweets <- filtered_tweets[order(-statuses_count)]
filtered_tweets[1:10, list(text = paste(substr(text, 1, 40), '...'), 
                           screen_name, statuses_count, lat, lon)]
```

Sample high-volume Tweeters
========================================================
class: small-code
```{r, echo=FALSE}
load(file = 'sample_filtered_tweets.RData')
print(sample_filtered_tweets)
```

Selecting a high-end user
========================================================
class: small-code
From the list of high-volume Tweeters, I sampled a few user's histories via the **twitteR::userTimeline** function. Twitter restricts the history to 3200 entries. I settled on a particular user, which I denote as *high_volume_user* below, and obtained their history as follows. To create a training data set for the classification model, I filtered the timeline Tweets to obtain only those that were geotagged:

```{r,eval=FALSE}
tweet_history_user = userTimeline(high_volume_user, n = 3200)
tweet_history_user <- data.table(twListToDF(tweet_history_user))
DT <- get_geo_tagged_data(tweet_history_user)
```

Feature engineering: adding travel distance
========================================================
class: small-code
People may limit their travel based on the distance, e.g., why go 50 miles
for ice cream when you go a few miles from home to get it? Our user, however,
traveled to the Philippines this last year and so we need to define the
distances he traveled relative to some center reference point, which we define
based on a simple kmeans clustering. 

Proof of clusters
========================================================
class: small-code
First, let's prove that we have two clusters of
data: one centered around the Pacific NW and one in the Philippines:

```{r, echo=FALSE}
load(file = 'training_pre_cluster.RData')
```

```{r}
invisible(DT[, plot(latitude, longitude, pch = 19)])
```

K-Means clustering
========================================================
class: small-code
Next, I use **stats::kmeans** to cluster the lat-lon values, which outputs cluster centers that we will use for travel distance:

```{r, eval=FALSE}
cluster <- kmeans(DT[, list(latitude, longitude)], centers = 2)
regions <- c('PACNW', 'PHILIPPINES')
if (cluster$centers[1L,1L] < 20) regions <- rev(regions) 
centers <- data.table(center_latitude = cluster$centers[,1L], 
                      center_longitude = cluster$centers[,2L], 
                      cluster_color = c('red','blue'),
                      region = regions,
                      key = 'region')

# merge clsuter information into training data for convenience
DT[, region := ifelse(cluster$cluster == 1L, regions[1L], regions[2L])]
setkey(DT, region)
DT <- DT[centers] # fast data.table merge
print(centers)
```

```{r,echo=FALSE}
load(file = 'clusters.RData')
print(centers)
```

Plotting the clusters
========================================================
class: super-small-code
Here, I develop a somewhat fancy function to plot the clusters with a map overlay to better visualize the Tweets:

```{r}
library(ggplot2)

# Define fancy plot function to better visualize clusters
plot_cluster <- function(data) {
  stopifnot(is.data.table(data))
  stopifnot(data[, length(unique(region))] == 1L)

  color <- data[, unique(cluster_color)]
  region <- data[, unique(region)]
  centers <- data[, list(latitude = unique(center_latitude), longitude = unique(center_longitude))]
  
  if (region == 'PHILIPPINES'){
    regional_map <- map_data('world', regions = 'Philippines')
    capital <- data.frame(latitude = 14.5995, longitude = 120.9842, name = 'Manila, Philippines')
  } else {
    regional_map <- map_data('county', region = c('washington'))
    capital <- data.frame(latitude = 47.0379, longitude = -122.9007, name = 'Olympia, WA')
  }
  
  g <- ggplot(regional_map) + 
    geom_map(aes(map_id = region), map = regional_map, fill = "white", color = "grey20", size = 0.25) +
    expand_limits(x = regional_map$long, y = regional_map$lat) +
    geom_point(data = data, aes(x = longitude, y = latitude), size = 3, alpha = 2/5, color = color) +
    geom_point(data = centers, 
               aes(x = longitude, y = latitude), size = 1.5, stroke = 1.5, alpha = 1, color = 'black', fill = 'white', shape = 21) +
    geom_point(data = capital, aes(x = longitude, y = latitude), size = 1, alpha = 1, 
               shape = 24, color = 'black', fill = 'black') +
    geom_point(data = capital, aes(x = longitude, y = latitude), size = 1, alpha = 1, 
               shape = 25, color = 'black', fill = 'black') +
    geom_text(data = capital, aes(x = longitude, y = latitude, label = name, hjust = -0.1)) +
    xlab('longitude') + ylab('latitude')
  
  print(g)
  
  return(invisible(g))
}

# plot the clusters
plot_cluster(DT[region == 'PACNW']); plot_cluster(DT[region == 'PHILIPPINES'])
```

Pacific Northwest cluster
========================================================
title: false
```{r pacnw_cluster,echo=FALSE,fig.width=8,fig.height=5,dpi=300,out.width="1920px",height="1080px"}
plot_cluster(DT[region == 'PACNW'])
```

Phillippines cluster
========================================================
title: false
```{r philippines_cluster,echo=FALSE,fig.width=8,fig.height=5,dpi=300,out.width="1920px",height="1080px"}
plot_cluster(DT[region == 'PHILIPPINES'])
```

Form distance from cluster centers
========================================================
class: super-small-code
```{r, eval=FALSE}
vincenty_distance <- function(p1, p2, r = 3963.190592) {
  # Vincenty elipsoid great circle distance between two points in miles
  miles_per_meter <- 0.000621371
  distVincentyEllipsoid(p1, p2) * miles_per_meter
}

DT[, dist_from_center := vincenty_distance(cbind(center_longitude, center_latitude), 
                                           cbind(longitude, latitude)), 
   by = region]

# Sample distances (miles)
ix <- 10:13
DT[, list(text = paste(substr(text[ix], 1, 50), '...'), 
          dist_from_center = dist_from_center[ix], 
          latitude = latitude[ix], 
          longitude = longitude[ix]), 
   by = region]
```
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'sample_distance.RData')
print(sample_distance)
options(old_opts)
```

Adding time features
========================================================
class: small-code
People tend to travel to different locations depending on the day of the week, the time of day, and even the season of the year. Skipping the details, I added many of these features as well by converting the datetime information packed with the Tweet accordingly. Here is a sample of these features:
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'sample_time.RData')
print(sample_time)
options(old_opts)
```

Adding weather data
========================================================
class: small-code
Weather also influences travel behavior. I gathered temperature and precipitation data from NOAA (<http://www.ncdc.noaa.gov/cdo-web/>) for the Seattle area and the Philippines and merged it with the Twitter data. Here is a sample:
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'sample_weather.RData')
print(sample_weather)
options(old_opts)
```

Parsing location via tweet text
========================================================
class: small-code
You may have noticed that the Tweets of the target user are mostly comprised of where they are at! Here are a few examples:
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'text_location_example.RData')
print(text_location_example)
options(old_opts)
```

Parsing location via tweet text (continued)
========================================================
class: small-code
I wrote code to filter the texts for location descriptions following **@** or **at** in the Tweet and then collapsed the resulting location words into a single word separated by underscores. The idea is to form a categorical variable identifying the location via parsed Tweets. Here are some samples:

Original text
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'parsed_locations.RData')
print(original_tweets)
```
Parsed location label
```{r,echo=FALSE}
print(parsed_tweet_locations)
options(old_opts)
```

Parsing location via tweet text (continued)
========================================================
class: small-code
Here is a list of the most frequently visited locations:
```{r,echo=FALSE}
old_opts <- options(width=150)
load(file = 'popular_locations.RData')
print(popular_locations)
options(old_opts)
```

Forming response variable
========================================================
class: small-code
```{r,eval=FALSE}
# Divide regional space by rounding the latitude and longitude to the nearest hundredth
# This will form regional categories that we can use in a classification model
DT[, lat_long := factor(paste(round(latitude, 2L), round(longitude, 2L), sep = ':'))]
```
